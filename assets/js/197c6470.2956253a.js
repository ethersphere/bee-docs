"use strict";(self.webpackChunkbee_docs=self.webpackChunkbee_docs||[]).push([[3152],{57668:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>u,contentTitle:()=>c,default:()=>g,frontMatter:()=>l,metadata:()=>h,toc:()=>p});var a=n(17624),r=n(4552),s=n(11504);const i=[[2,3,3,3,3,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9],[4,5,5,6,6,6,7,7,7,7,8,8,8,8,8,9,9,9,9,9,10,10,10,10,10,10,11,11,11,11,11,11,12,12,12,12,12,12,12,13,13,13,13,13,13,13,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,21,21,21],[5,6,7,8,8,9,9,9,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,15,16,16,16,17,17,17,17,18,18,18,18,19,19,19,19,20,20,20,20,21,21,21,21,21,22,22,22,22,23,23,23,23,23,24,24,24,24,25,25,25,25,25,26,26,26,26,26,27,27,27,27,28,28,28,28,28,29,29,29,29,29,30,30,30,30,30,31,31,31,31,31],[19,23,26,29,31,34,36,38,40,43,45,47,48,50,52,54,56,58,59,61,63,65,66,68,70,71,73,75,76]];const d=[[3,3,4,4,4,4,4,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9],[5,6,6,7,7,8,8,9,9,9,10,10,10,10,11,11,11,12,12,12,13,13,13,13,14,14,14,15,15,15,15,16,16,16,16,17,17,17,17,18,18,18,18,18,19,19,19,19,20,20,20,20,20,21],[6,8,9,9,10,11,12,12,13,14,14,15,15,16,17,17,18,18,19,19,20,20,21,21,21,22,22,23,23,24,24,25,25,25,26,26,27,27,28,28,28,29,29,30,30,30,31,31],[23,29,34,38,43,47,50,54,58,61,65,68,71,75,78,81,84,87]];function o(){const[e,t]=(0,s.useState)(""),[n,r]=(0,s.useState)([]),[o,l]=(0,s.useState)(""),[c,h]=(0,s.useState)(""),[u,p]=(0,s.useState)(!1),[x,g]=(0,s.useState)("chunks"),f=[119,107,97,37],m=[9,21,31,89],v=[59,53,48,18],j={Medium:"1%",Strong:"5%",Insane:"10%",Paranoid:"50%"},y={container:{padding:"20px",fontFamily:"Arial",maxWidth:"650px",margin:"0 auto"},title:{margin:"10px 0"},input:{padding:"8px",margin:"5px 0",width:"50%"},select:{padding:"8px",margin:"5px 0",width:"50%"},button:{padding:"10px 15px",margin:"10px 0",cursor:"pointer"},result:{margin:"10px 0",fontWeight:"bold"},table:{width:"100%",borderCollapse:"collapse"},tdName:{border:"1px solid #ccc",padding:"4px 8px",textAlign:"left"},tdValue:{border:"1px solid #ccc",padding:"4px 8px",textAlign:"right"},bold:{fontWeight:"bold"}};return(0,a.jsxs)("div",{style:y.container,children:[(0,a.jsxs)("div",{children:[(0,a.jsx)("div",{style:y.title,children:"Data Size:"}),(0,a.jsx)("input",{placeholder:"Enter data size",type:"number",value:o,onChange:e=>{l(e.target.value)},style:y.input}),(0,a.jsx)("div",{style:y.title,children:"Data Unit:"}),(0,a.jsxs)("select",{value:x,onChange:e=>{g(e.target.value)},style:y.select,children:[(0,a.jsx)("option",{value:"chunks",children:"Chunks"}),(0,a.jsx)("option",{value:"kb",children:"KB"}),(0,a.jsx)("option",{value:"gb",children:"GB"})]}),(0,a.jsx)("div",{style:y.title,children:"Redundancy Level:"}),(0,a.jsxs)("select",{value:c,onChange:e=>{h(e.target.value)},style:y.select,children:[(0,a.jsx)("option",{value:"",disabled:!0,children:"Select Redundancy Level"}),(0,a.jsx)("option",{value:"Medium",children:"Medium"}),(0,a.jsx)("option",{value:"Strong",children:"Strong"}),(0,a.jsx)("option",{value:"Insane",children:"Insane"}),(0,a.jsx)("option",{value:"Paranoid",children:"Paranoid"})]}),(0,a.jsxs)("div",{style:y.title,children:[(0,a.jsx)("input",{type:"checkbox",checked:u,onChange:()=>{p(!u)}})," Use Encryption?"]}),e&&(0,a.jsx)("div",{style:{color:"red",marginTop:"10px"},children:e}),(0,a.jsx)("button",{onClick:()=>{if(t(""),r([]),!c)return void t("Please select a redundancy level.");let e,n,a,s;if("kb"===x){const a=parseFloat(o);if(isNaN(a)||a<=0)return void t("Please input a valid KB value above 0.");n=a,e=Math.ceil(1024*a/4096)}else if("gb"===x){const r=parseFloat(o);if(isNaN(r)||r<=0)return void t("Please input a valid GB value above 0.");a=r,n=1024*r*1024,e=Math.ceil(1024*n/4096)}else{const a=parseFloat(o);if(isNaN(a)||a<=0)return void t("Please input a valid chunk amount above 0.");e=Math.ceil(a),n=4096*e/1024}const l={Medium:0,Strong:1,Insane:2,Paranoid:3}[c],h=u?Math.floor(e/v[l]):Math.floor(e/f[l]),p=u?e%v[l]:e%f[l],g=p-1<0?0:p-1,y=(u?d:i)[l][g]||0,b=h*m[l]+y,w=(e+b-e)/e*100,k=4096*b/1024;"gb"===x&&(s=k/1048576);const C=e=>new Intl.NumberFormat("en-US").format(e),E=[{name:"Source data size",value:"gb"===x?C(a.toFixed(2))+" GB":C(n.toFixed(0))+" KB"},{name:"Parity data size",value:"gb"===x?C(s.toFixed(2))+" GB":C(k.toFixed(0))+" KB"},{name:"Source data in chunks",value:C(e)},{name:"Additional parity chunks",value:C(b)},{name:"Percent cost increase",value:w.toFixed(2)+"%"},{name:"Selected redundancy level",value:""+c},{name:"Error tolerance",value:j[c]}];r(E)},style:y.button,children:"Calculate"})]}),(0,a.jsx)("div",{style:y.result,children:(0,a.jsx)("table",{style:y.table,children:(0,a.jsx)("tbody",{children:n.map(((e,t)=>(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{style:{...y.tdName,...y.bold},children:e.name})," ",(0,a.jsx)("td",{style:y.tdValue,children:e.value})]},t)))})})})]})}const l={title:"Erasure Coding",id:"erasure-coding"},c=void 0,h={id:"develop/access-the-swarm/erasure-coding",title:"Erasure Coding",description:"Erasure coding is a powerful method for safeguarding data, offering robust protection against partial data loss. This technique involves dividing the original data into multiple fragments and generating extra parity fragments to introduce redundancy. A key advantage of erasure coding is its ability to recover the complete original data even if some fragments are lost. Additionally, it offers the flexibility to customize the level of data loss protection, making it a versatile and reliable choice for preserving data integrity on Swarm. For a more in depth dive into erasure coding on Swarm, see the erasure coding paper from the Swarm research team.",source:"@site/docs/develop/access-the-swarm/erasure-coding.md",sourceDirName:"develop/access-the-swarm",slug:"/develop/access-the-swarm/erasure-coding",permalink:"/docs/develop/access-the-swarm/erasure-coding",draft:!1,unlisted:!1,editUrl:"https://github.com/ethersphere/docs.github.io/blob/master/docs/develop/access-the-swarm/erasure-coding.md",tags:[],version:"current",frontMatter:{title:"Erasure Coding",id:"erasure-coding"},sidebar:"develop",previous:{title:"Upload and Download",permalink:"/docs/develop/access-the-swarm/upload-and-download"},next:{title:"Direct upload",permalink:"/docs/develop/access-the-swarm/direct-upload"}},u={},p=[{value:"Uploading With Erasure Coding",id:"uploading-with-erasure-coding",level:2},{value:"Redundancy Level Costs Explained",id:"redundancy-level-costs-explained",level:3},{value:"Cost Calculator Widget",id:"cost-calculator-widget",level:2},{value:"Downloading Erasure Encoded Data",id:"downloading-erasure-encoded-data",level:2},{value:"Default Download Behaviour",id:"default-download-behaviour",level:3},{value:"Options",id:"options",level:3}];function x(e){const t={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.M)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(t.p,{children:["Erasure coding is a powerful method for safeguarding data, offering robust protection against partial data loss. This technique involves dividing the original data into multiple fragments and generating extra parity fragments to introduce redundancy. A key advantage of erasure coding is its ability to recover the complete original data even if some fragments are lost. Additionally, it offers the flexibility to customize the level of data loss protection, making it a versatile and reliable choice for preserving data integrity on Swarm. For a more in depth dive into erasure coding on Swarm, see the ",(0,a.jsx)(t.a,{href:"https://papers.ethswarm.org/p/erasure/",children:"erasure coding paper"})," from the Swarm research team."]}),"\n",(0,a.jsx)(t.h2,{id:"uploading-with-erasure-coding",children:"Uploading With Erasure Coding"}),"\n",(0,a.jsxs)(t.p,{children:["Erasure coding is available for the ",(0,a.jsx)(t.a,{href:"/api/#tag/Bytes",children:(0,a.jsx)(t.code,{children:"/bytes"})})," and ",(0,a.jsx)(t.a,{href:"/api/#tag/BZZ",children:(0,a.jsx)(t.code,{children:"/bzz"})})," endpoints, however it is not available for the ",(0,a.jsx)(t.a,{href:"/api/#tag/Chunk",children:(0,a.jsx)(t.code,{children:"/chunks"})})," endpoint which deals with single chunks. Since erasure coding relies on splitting data into chunks and the chunk is the smallest unit of data within Swarm which cannot be further subdivided, erasure coding is not applicable for the ",(0,a.jsx)(t.code,{children:"/chunks"})," endpoint which deals with single chunks."]}),"\n",(0,a.jsxs)(t.p,{children:["To upload data to Swarm using erasure coding, the ",(0,a.jsx)(t.code,{children:"swarm-redundancy-level: <integer>"})," header is used:"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:'    curl \\\n        -X POST http://localhost:1633/bzz?name=test.txt \\\n        -H "swarm-redundancy-level: 4" \\\n        -H "swarm-postage-batch-id: 27d1bbef6c01e266d3130c01c9be60fd76b4a69d6f8ea6291548e1644bcf9001" \\\n        -H "Content-Type: text/plain" \n\n    {"reference":"c02e7d943fbc0e753540f377853b7181227a83e773870847765143681511c97d"}\n'})}),"\n",(0,a.jsxs)(t.p,{children:["The accepted values for the ",(0,a.jsx)(t.code,{children:"swarm-redundancy-level"})," header range from the default of 0 up to 4. Each level corresponds to a different level of data protection, with erasure coding turned off at 0, and at its maximum at 4. Each increasing level provides increasing amount of data redundancy offering greater protection against data loss. Each level has been formulated to guarantee against a certain percentage of chunk retrieval errors, shown in the table below. As long as the error rate is below the expected chunk retrieval rate for the given level, there is a less than 1 in a million chance of failure to retrieve the source data."]}),"\n",(0,a.jsxs)(t.table,{children:[(0,a.jsx)(t.thead,{children:(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.th,{children:"Redundancy Level"}),(0,a.jsx)(t.th,{children:"Pseudonym"}),(0,a.jsx)(t.th,{children:"Expected Chunk Retrieval Error Rate"})]})}),(0,a.jsxs)(t.tbody,{children:[(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{children:"0"}),(0,a.jsx)(t.td,{children:"None"}),(0,a.jsx)(t.td,{children:"0%"})]}),(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{children:"1"}),(0,a.jsx)(t.td,{children:"Medium"}),(0,a.jsx)(t.td,{children:"1%"})]}),(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{children:"2"}),(0,a.jsx)(t.td,{children:"Strong"}),(0,a.jsx)(t.td,{children:"5%"})]}),(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{children:"3"}),(0,a.jsx)(t.td,{children:"Insane"}),(0,a.jsx)(t.td,{children:"10%"})]}),(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{children:"4"}),(0,a.jsx)(t.td,{children:"Paranoid"}),(0,a.jsx)(t.td,{children:"50%"})]})]})]}),"\n",(0,a.jsx)(t.h3,{id:"redundancy-level-costs-explained",children:"Redundancy Level Costs Explained"}),"\n",(0,a.jsx)(t.p,{children:"Erasure encoding is applied to sets of chunks of at most size 128 (including both data chunks and parity chunks). For higher levels of redundancy, the ratio of parity chunks to data chunks increases, increasing the percent cost of the upload compared to uploading at lower levels of redundancy."}),"\n",(0,a.jsx)(t.p,{children:"In the table below, the percent cost is displayed for each redundancy level. The cost of encrypted uploads is also shown, and is double the cost of un-encrypted uploads."}),"\n",(0,a.jsxs)(t.table,{children:[(0,a.jsx)(t.thead,{children:(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.th,{children:"Redundancy"}),(0,a.jsx)(t.th,{children:"Parities"}),(0,a.jsx)(t.th,{children:"Data Chunks"}),(0,a.jsx)(t.th,{children:"Percent"}),(0,a.jsx)(t.th,{children:"Chunks Encrypted"}),(0,a.jsx)(t.th,{children:"Percent Encrypted"})]})}),(0,a.jsxs)(t.tbody,{children:[(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{children:"Medium"}),(0,a.jsx)(t.td,{children:"9"}),(0,a.jsx)(t.td,{children:"119"}),(0,a.jsx)(t.td,{children:(0,a.jsx)(t.em,{children:"7.6%"})}),(0,a.jsx)(t.td,{children:"59"}),(0,a.jsx)(t.td,{children:"15%"})]}),(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{children:"Strong"}),(0,a.jsx)(t.td,{children:"21"}),(0,a.jsx)(t.td,{children:"107"}),(0,a.jsx)(t.td,{children:(0,a.jsx)(t.em,{children:"19.6%"})}),(0,a.jsx)(t.td,{children:"53"}),(0,a.jsx)(t.td,{children:"40%"})]}),(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{children:"Insane"}),(0,a.jsx)(t.td,{children:"31"}),(0,a.jsx)(t.td,{children:"97"}),(0,a.jsx)(t.td,{children:"32%"}),(0,a.jsx)(t.td,{children:"48"}),(0,a.jsx)(t.td,{children:"65%"})]}),(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{children:"Paranoid"}),(0,a.jsx)(t.td,{children:"89"}),(0,a.jsx)(t.td,{children:"37"}),(0,a.jsx)(t.td,{children:"240.5%"}),(0,a.jsx)(t.td,{children:"18"}),(0,a.jsx)(t.td,{children:"494%"})]})]})]}),"\n",(0,a.jsx)(t.p,{children:'For larger uploads (where the source data chunks are equal to or greater than the  "Data Chunks" for each redundancy level respectively) you can use the percent values shown in the "Percent" column as a general estimate of the percent cost of uploading. If the number of chunks is slightly less than the number shown in the "Data Chunks" column, you can also use the value in the "Percent" column as a good general estimate of the percent cost.'}),"\n",(0,a.jsxs)(t.p,{children:['However, if the number of source data chunks are significantly less than the value in the "Data Chunks" column for each respective level, then the percent cost will differ significantly from the one shown in the "Percent" column. For more precise calculations, see the ',(0,a.jsx)(t.a,{href:"/docs/learn/advanced/erasure-cost-calculation",children:"relevant appendix"}),"."]}),"\n",(0,a.jsx)(t.h2,{id:"cost-calculator-widget",children:"Cost Calculator Widget"}),"\n",(0,a.jsx)(t.p,{children:"This calculator takes as input an amount of data and an erasure coding redundancy level, and outputs the number of additional parity chunks required to erasure code that amount of data as well as the increase in cost to upload vs. a non-erasure encoded upload:"}),"\n",(0,a.jsx)(o,{}),"\n",(0,a.jsx)(t.h2,{id:"downloading-erasure-encoded-data",children:"Downloading Erasure Encoded Data"}),"\n",(0,a.jsxs)(t.p,{children:["For a downloader, the process for downloading a file which has been erasure encoded does not require any changes from the ",(0,a.jsx)(t.a,{href:"/docs/develop/access-the-swarm/upload-and-download",children:"normal download process"}),". There are several options for adjusting the default behaviour for erasure encoded downloads, however there is no need to adjust them."]}),"\n",(0,a.jsx)(t.h3,{id:"default-download-behaviour",children:"Default Download Behaviour"}),"\n",(0,a.jsx)(t.p,{children:"Erasure coding retrieval for downloads is enabled by default, so there is no need for a downloader to explicitly enable the feature. The default download behaviour is to use the DATA strategy with fallback enabled. With these settings, first an attempt will be made to download the data chunks only. If any of the data chunks are missing, then the retrieval method will fall back to the RACE strategy (PROX is not currently implemented and so will be skipped). With the RACE strategy, an attempt will be made to download all data and parity chunks, and chunks will continue to be downloaded until enough have been retrieved to reconstruct the original data."}),"\n",(0,a.jsx)(t.h3,{id:"options",children:"Options"}),"\n",(0,a.jsx)(t.admonition,{type:"warning",children:(0,a.jsx)(t.p,{children:"Do not adjust these options unless you know exactly what you are doing. The default settings are the best option for almost all cases."})}),"\n",(0,a.jsxs)(t.p,{children:["When downloading erasure encoded data, there are three related headers which may be used: ",(0,a.jsx)(t.code,{children:"swarm-redundancy-strategy"}),", ",(0,a.jsx)(t.code,{children:"swarm-redundancy-fallback-mode: <integer>"}),", and ",(0,a.jsx)(t.code,{children:"swarm-chunk-retrieval-timeout"}),"."]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.code,{children:"swarm-redundancy-strategy"}),":  This header allows you to set the retrieval strategy for fetching chunks. The accepted values range from 0 to 3. Each number corresponds to a different chunk retrieval strategy. The numbers stand for the NONE, DATA, PROX and RACE strategies respectively which are described in greater detail in ",(0,a.jsx)(t.a,{href:"/api/#tag/BZZ",children:"the API reference"})," (also see ",(0,a.jsx)(t.a,{href:"https://papers.ethswarm.org/p/erasure/",children:"the erasure code paper"})," for even more in-depth descriptions).  With each increasing level, there will be a potentially greater bandwidth cost."]}),"\n",(0,a.jsx)(t.admonition,{title:"Retrieval Strategies",type:"info",children:(0,a.jsxs)(t.ol,{start:"0",children:["\n",(0,a.jsx)(t.li,{children:"NONE: This strategy is based on direct retrieval of data chunks without pre-fetching, with parity chunks ignored. No pre-fetching is used (data chunks are fetched sequentially)."}),"\n",(0,a.jsx)(t.li,{children:"DATA: The same as NONE, except that data chunks are pre-fetched (data chunks are fetched in parallel in order to reduce latency)."}),"\n",(0,a.jsxs)(t.li,{children:["PROX: For this strategy, the chunks closest (in Kademlia distance) to the node are retrieved first. ",(0,a.jsx)(t.em,{children:"(Not yet implemented.)"})]}),"\n",(0,a.jsx)(t.li,{children:"RACE: Initiates requests for all data and parity chunks and continues to retrieve chunks until enough chunks are retrieved that the original data can be reconstructed."}),"\n"]})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.code,{children:"swarm-redundancy-fallback-mode: <boolean>"}),": Enables the fallback feature for the redundancy strategies so that if one of the retrieval strategies fails, it will fallback to the more intensive strategy until retrieval is successful or retrieval fails. Default is ",(0,a.jsx)(t.code,{children:"true"}),"."]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.code,{children:"swarm-chunk-retrieval-timeout: <boolean>"}),": Allows you to specify the timeout time for chunk retrieval with a default value of 30 seconds. ",(0,a.jsx)(t.em,{children:"(This is primarily used by the Bee development team for testing and it's recommended that Bee users do not need to use this option.)"})]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"An example download request may look something like this:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:'    curl -OJL \\\n    -H "swarm-redundancy-strategy: 3" \\\n    -H "swarm-redundancy-fallback-mode: true" \\\n     http://localhost:1633/bzz/c02e7d943fbc0e753540f377853b7181227a83e773870847765143681511c97d/\n\n       % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n'})}),"\n",(0,a.jsx)(t.p,{children:"For this request, the redundancy strategy is set to 3 (RACE), which means that it will initiate a request for all data and parity chunks and continue to retrieve chunks until enough have been retrieved to reconstruct the source data. This is in contrast with the default strategy of DATA where only the data chunks will be retrieved."}),"\n",(0,a.jsxs)(t.p,{children:["However, as noted above, it is recommended to not adjust the default settings for these options, so a typical request would actually look like this (which is the exact same as a ",(0,a.jsx)(t.a,{href:"/docs/develop/access-the-swarm/upload-and-download",children:"normal download"})," without any additional options set):"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"    curl -OJL http://localhost:1633/bzz/c02e7d943fbc0e753540f377853b7181227a83e773870847765143681511c97d/\n\n       % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n"})}),"\n",(0,a.jsx)(t.p,{children:"This means that there is no need for you to inform downloaders that a file you have uploaded uses erasure coding, as even with the default download behaviour reconstruction of the source file will be attempted if any chunks are missing."})]})}function g(e={}){const{wrapper:t}={...(0,r.M)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(x,{...e})}):x(e)}},4552:(e,t,n)=>{n.d(t,{I:()=>d,M:()=>i});var a=n(11504);const r={},s=a.createContext(r);function i(e){const t=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function d(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),a.createElement(s.Provider,{value:t},e.children)}}}]);