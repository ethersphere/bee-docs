"use strict";(self.webpackChunkbee_docs=self.webpackChunkbee_docs||[]).push([[7183],{28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>i});var s=t(96540);const o={},a=s.createContext(o);function r(e){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),s.createElement(a.Provider,{value:n},e.children)}},60829:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>h,contentTitle:()=>d,default:()=>u,frontMatter:()=>i,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"concepts/DISC/disc","title":"DISC","description":"DISC (Distributed Immutable Storage of Chunks) is a storage solution developed by Swarm based on a modified implementation of a Kademlia DHT which has been specialized for data storage. Swarm\'s implementation of a DHT differs significantly in that it stores the content in the DHT directly, rather than just storing a list of seeders who are able to serve the content. This approach allows for much faster and more efficient retrieval of data.","source":"@site/docs/concepts/DISC/DISC.mdx","sourceDirName":"concepts/DISC","slug":"/concepts/DISC/","permalink":"/docs/concepts/DISC/","draft":false,"unlisted":false,"editUrl":"https://github.com/ethersphere/docs.github.io/blob/master/docs/concepts/DISC/DISC.mdx","tags":[],"version":"current","frontMatter":{"title":"DISC","id":"disc"},"sidebar":"concepts","previous":{"title":"What is Swarm?","permalink":"/docs/concepts/what-is-swarm"},"next":{"title":"Kademlia","permalink":"/docs/concepts/DISC/kademlia"}}');var o=t(74848),a=t(28453);const r=t.p+"assets/images/bos_fig_2_7-160d775553d44403c5773971ab62c7bc.jpg",i={title:"DISC",id:"disc"},d=void 0,h={},c=[{value:"Kademlia Topology and Routing",id:"kademlia-topology-and-routing",level:3},{value:"Neighborhoods",id:"neighborhoods",level:3},{value:"Chunks",id:"chunks",level:3},{value:"Content-Addressed Chunks and Single-Owner Chunks",id:"content-addressed-chunks-and-single-owner-chunks",level:4},{value:"Push-Sync, Pull-Sync, and Retrieval Protocols",id:"push-sync-pull-sync-and-retrieval-protocols",level:3}];function l(e){const n={a:"a",em:"em",h3:"h3",h4:"h4",p:"p",strong:"strong",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(n.p,{children:["DISC (Distributed Immutable Storage of Chunks) is a storage solution developed by Swarm based on a modified implementation of a ",(0,o.jsx)(n.a,{href:"/docs/concepts/DISC/kademlia",children:"Kademlia DHT"})," which has been specialized for data storage. Swarm's implementation of a DHT differs significantly in that it stores the content in the DHT directly, rather than just storing a list of seeders who are able to serve the content. This approach allows for much faster and more efficient retrieval of data."]}),"\n",(0,o.jsx)(n.h3,{id:"kademlia-topology-and-routing",children:"Kademlia Topology and Routing"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"/docs/concepts/DISC/kademlia",children:"Kademlia"})," is a distributed hash table (DHT) widely used in peer-to-peer networks such as Ethereum and Bittorent. It serves as the routing and topology foundation for communication between nodes in the Swarm netowrk. It organizes nodes based on their overlay addresses and ensures that messages are relayed efficiently, even in a dynamic, decentralized environment."]}),"\n",(0,o.jsx)(n.p,{children:'One of the advantages of using Kademlia as a model for network topology is that both the number of forwarding "hops" required to route a chunk to its destination and the number of peer connections required to maintain Kademlia topology are logarithmic to the size of the network (a minimum of two connections is required in order to maintain Kademlia topology in case of network churn - nodes dropping in and out of the network). This makes Swarm a highly scalable system which is efficient even at very large scales.'}),"\n",(0,o.jsx)(n.h3,{id:"neighborhoods",children:"Neighborhoods"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"/docs/concepts/DISC/neighborhoods",children:"Neighborhoods"})," are groups of nodes which are responsible for sharing the same chunks. The chunks which each neighborhood is responsible for storing are defined by the proximity order of the nodes and the chunks. In other words, each node is responsible for storing chunks with which their overlay addresses share a certain number of prefix bits, and together with other nodes which share the same prefix bits, make up neighborhoods which share the responsibility for storing the same chunks."]}),"\n",(0,o.jsxs)(n.p,{children:["Neighborhoods play a key role in providing data redundancy for chunks stored on Swarm since each node in a neighborhood will keep copies of the same chunks. The optional ",(0,o.jsx)(n.a,{href:"/docs/concepts/DISC/erasure-coding",children:"erasure coding"})," feature can also be enabled for added redundancy and greater data protection."]}),"\n",(0,o.jsx)(n.h3,{id:"chunks",children:"Chunks"}),"\n",(0,o.jsxs)(n.p,{children:["In the DISC model, chunks are the canonical unit of data. When a file is uploaded to Swarm, it gets broken down into 4kb pieces with attached metadata. The pieces then get distributed amongst nodes in the Swarm network based on their ",(0,o.jsx)(n.a,{href:"/docs/references/glossary#overlay",children:"overlay addresses"}),". There are two fundamental chunk types: content-addressed chunks and single-owner chunks."]}),"\n",(0,o.jsx)(n.h4,{id:"content-addressed-chunks-and-single-owner-chunks",children:"Content-Addressed Chunks and Single-Owner Chunks"}),"\n",(0,o.jsx)(n.p,{children:"Content-addressed chunks are chunks whose address is based on the hash digest of their data. Using a hash as the chunk address makes it possible to verify the integrity of chunk data. Swarm uses the BMT hash function based on a binary Merkle tree over small segments of the chunk data. A content-addressed chunk has an at most 4KB payload, and its address is calculated as the hash of the span (chunk metadata) and the Binary Merkle Tree hash of the payload."}),"\n",(0,o.jsxs)("div",{style:{textAlign:"center"},children:[(0,o.jsx)("img",{src:r,className:"responsive-image"}),(0,o.jsx)("p",{style:{fontStyle:"italic",marginTop:"0.5rem"},children:(0,o.jsxs)(n.p,{children:["Source: ",(0,o.jsx)("a",{href:"https://www.ethswarm.org/the-book-of-swarm-2.pdf#subsection.2.2.2",target:"_blank",children:'The Book of Swarm - Figure 2.7 - "Content addressed chunk"'})]})})]}),"\n",(0,o.jsx)(n.p,{children:"For single-owner chunks on the other hand, the address is calculated as the hash of a unique id and the owner's overlay address. The content consists of an arbitrary data payload along with required headers. Unlike a content-addressed chunk, the contents of a single-owner chunk may be updated while the address remains unchanged. Single owner chunks form the basis for feeds, which are data structures that allow for mutable content with a static address."}),"\n",(0,o.jsx)(n.h3,{id:"push-sync-pull-sync-and-retrieval-protocols",children:"Push-Sync, Pull-Sync, and Retrieval Protocols"}),"\n",(0,o.jsxs)(n.p,{children:["When a file is first uploaded to Swarm, it gets broken down by the uploading Bee node chunks which are then distributed amongst other Bee nodes in the Swarm network. Chunks get distributed to the target neighborhood by the ",(0,o.jsx)(n.em,{children:(0,o.jsx)(n.strong,{children:"push-sync"})})," protocol. Once a chunk reaches its destination, it will then be duplicated and synced to other nodes in order to achieve data redundancy through the ",(0,o.jsx)(n.em,{children:(0,o.jsx)(n.strong,{children:"pull-sync"})})," protocol. The pull-sync protocol operates continuously as nodes enter or exit the network \u2013 ensuring that data redundancy is always maintained. When a client node requests a file for download, its request gets forwarded by the ",(0,o.jsx)(n.em,{children:(0,o.jsx)(n.strong,{children:"retrieval-protocol"})})," to all the nodes storing the relevant chunks, and then those chunks get returned to the requesting node and the file gets reconstructed from its constituent chunks."]})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}}}]);